{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "appointed-indie",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-12T19:41:36.130591Z",
     "start_time": "2021-03-12T19:41:35.681637Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.pipeline        import Pipeline\n",
    "from sklearn.preprocessing   import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute          import SimpleImputer\n",
    "from sklearn.compose         import ColumnTransformer\n",
    "from sklearn.metrics         import *\n",
    "from sklearn.base            import BaseEstimator\n",
    "\n",
    "from sklearn.linear_model    import LogisticRegression, RidgeClassifier\n",
    "from sklearn.naive_bayes     import BernoulliNB, GaussianNB\n",
    "from sklearn.tree            import DecisionTreeClassifier\n",
    "from sklearn.ensemble        import RandomForestClassifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "editorial-viewer",
   "metadata": {},
   "source": [
    "## Research Question:\n",
    "Can we use a machine learning model to predict whether or not a person will earn $50,000.00 per year based on their demographics?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "illegal-parade",
   "metadata": {},
   "source": [
    "## Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "naked-syria",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-12T19:41:36.825900Z",
     "start_time": "2021-03-12T19:41:36.132310Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48842, 10)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = 'https://raw.githubusercontent.com/pnavo/ml_project_sp21/main/income_data.csv'\n",
    "data = pd.read_csv(url, index_col=[0])\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cheap-thanksgiving",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-12T19:41:36.839504Z",
     "start_time": "2021-03-12T19:41:36.827917Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workClass</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>native-country</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>7</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age         workClass  education-num      marital-status  \\\n",
       "0   39         State-gov             13       Never-married   \n",
       "1   50  Self-emp-not-inc             13  Married-civ-spouse   \n",
       "2   38           Private              9            Divorced   \n",
       "3   53           Private              7  Married-civ-spouse   \n",
       "4   28           Private             13  Married-civ-spouse   \n",
       "\n",
       "          occupation   relationship   race     sex native-country  income  \n",
       "0       Adm-clerical  Not-in-family  White    Male  United-States       0  \n",
       "1    Exec-managerial        Husband  White    Male  United-States       0  \n",
       "2  Handlers-cleaners  Not-in-family  White    Male  United-States       0  \n",
       "3  Handlers-cleaners        Husband  Black    Male  United-States       0  \n",
       "4     Prof-specialty           Wife  Black  Female           Cuba       0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "original-average",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-12T19:41:36.847190Z",
     "start_time": "2021-03-12T19:41:36.841546Z"
    }
   },
   "outputs": [],
   "source": [
    "y = data[data.columns[-1]]\n",
    "X = data[data.columns[:-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "anonymous-semester",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-12T19:41:36.864585Z",
     "start_time": "2021-03-12T19:41:36.848513Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "X_train, X_validation, y_train, y_validation = train_test_split(X_train, y_train, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "minus-funeral",
   "metadata": {},
   "source": [
    "### Fit initial model\n",
    "\n",
    "When fitting the intial model, we'll need to arrange it in a pipeline so the algorithms can read our data properly.The `con_pipe` will be using `StandardScaler()` to standardize the numeric features, and I used `OneHotEncoder()` to convert all categorical features in the `cat_pipe` into a categorical numeric array. `SimpleImputer()` will be used to handle any cases of missing values, using the median value for the numeric features and the most frequently occuring values for the categorical features.\n",
    "\n",
    "Once those features have been cleaned and transformed, they can be combined with `ColumnTransformer()` and fit into a `Pipeline()` to get an intial machine learning model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "consolidated-harris",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-12T19:41:37.051730Z",
     "start_time": "2021-03-12T19:41:36.866029Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score:          0.6309\n",
      "F1 weighted score: 0.6356\n",
      "Balanced accuracy: 0.6356\n"
     ]
    }
   ],
   "source": [
    "# Find the categorical columns\n",
    "categorical_columns = (X.dtypes == object)\n",
    "\n",
    "# Setup preprocessing pipelines based on data types\n",
    "con_pipe = Pipeline([('scaler', StandardScaler()),\n",
    "                     ('imputer', SimpleImputer(strategy='median', add_indicator=True))])\n",
    "\n",
    "cat_pipe = Pipeline([('ohe', OneHotEncoder(handle_unknown='ignore')),\n",
    "                     ('imputer', SimpleImputer(strategy='most_frequent', add_indicator=True))])\n",
    "\n",
    "preprocessing = ColumnTransformer([('categorical', cat_pipe,  categorical_columns),\n",
    "                                   ('continuous',  con_pipe, ~categorical_columns),\n",
    "                                   ])\n",
    "\n",
    "pipe = Pipeline([('preprocessing', preprocessing), \n",
    "                 ('clf', LogisticRegression(solver='liblinear'))])\n",
    "pipe.fit(X_train, y_train)\n",
    "\n",
    "y_pred = pipe.predict(X_validation)\n",
    "\n",
    "f1_weighted = f1_score(y_validation, y_pred, average = 'weighted')\n",
    "f1          = f1_score(y_validation, y_pred)\n",
    "bac         = balanced_accuracy_score(y_validation, y_pred)\n",
    "\n",
    "print(f'F1 score:          {f1:.4f}')\n",
    "print(f'F1 weighted score: {f1_weighted:.4f}')\n",
    "print(f'Balanced accuracy: {bac:.4f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "german-festival",
   "metadata": {},
   "source": [
    "I chose the F1 scores to get a good balance on precision and accuracy, and also to use the additional arguement to determine if the data is imbalanced. The balanced accuracy score is used as a comparison to the F1 scores.\n",
    "\n",
    "## Searching for best linear model\n",
    "\n",
    "Using the `DummyEstimator()` class as a placeholder, I'll create a search space that the `RandomizedSearchCV()` can iterate through and test different models and hyperparameters to return a best model that we can use as a comparison to the inital model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "strategic-glasgow",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-12T19:41:37.055292Z",
     "start_time": "2021-03-12T19:41:37.053143Z"
    }
   },
   "outputs": [],
   "source": [
    "class DummyEstimator(BaseEstimator):\n",
    "    def fit(self): pass\n",
    "    def score(self): pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "several-tablet",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-12T19:41:37.061548Z",
     "start_time": "2021-03-12T19:41:37.058511Z"
    }
   },
   "outputs": [],
   "source": [
    "search = [{'algo': [LogisticRegression()],\n",
    "           'algo__penalty': ['l1','l2'],\n",
    "           'algo__class_weight': ['balanced', None],\n",
    "           'algo__solver': ['liblinear', 'newton-cg']},\n",
    "          \n",
    "          {'algo': [RidgeClassifier()],\n",
    "           'algo__normalize': [True,False],\n",
    "           'algo__max_iter': [10,100,1000]},\n",
    "          \n",
    "          {'algo': [BernoulliNB()],\n",
    "           'algo__alpha': [1e-6, 1e-3, 0, 0.5, 1, 1e3, 1e6],\n",
    "           'algo__fit_prior': [True, False]},\n",
    "          \n",
    "          {'algo': [GaussianNB()],\n",
    "           'algo__var_smoothing': [1e-9, 1e-6, 1e-3, 1, 1e3, 1e6]}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dress-dragon",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-12T19:41:37.065439Z",
     "start_time": "2021-03-12T19:41:37.063609Z"
    }
   },
   "outputs": [],
   "source": [
    "pipe = Pipeline([('preprocessing', preprocessing), \n",
    "                 ('algo', DummyEstimator())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "headed-graham",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-12T19:41:45.118359Z",
     "start_time": "2021-03-12T19:41:37.066817Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:    1.6s\n",
      "[Parallel(n_jobs=-1)]: Done 150 out of 150 | elapsed:    7.9s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(RidgeClassifier(max_iter=10), 0.6349226149673075)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand_algos = RandomizedSearchCV(estimator=pipe, \n",
    "                                param_distributions=search, \n",
    "                                n_iter=30,\n",
    "                                cv=5, \n",
    "                                scoring='f1_weighted',\n",
    "                                n_jobs=-1,\n",
    "                                verbose=1,\n",
    "                                random_state=42)\n",
    "\n",
    "best_model = rand_algos.fit(X_train, y_train)\n",
    "results    = rand_algos.cv_results_\n",
    "\n",
    "best_model.best_estimator_.get_params()['algo'], best_model.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "affecting-equipment",
   "metadata": {},
   "source": [
    "## Searching for best Trees models\n",
    "\n",
    "Performing the same method as with the linear model searches above, but wanted to give `DescisionTreeClassifier()` and `RandomForestClassifier()` their own search space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "appropriate-recommendation",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-12T19:41:45.123488Z",
     "start_time": "2021-03-12T19:41:45.119862Z"
    }
   },
   "outputs": [],
   "source": [
    "trees = [{'algo': [DecisionTreeClassifier()],\n",
    "          'algo__splitter': ['best','random'],\n",
    "          'algo__max_depth': [None, 5, 10, 20],\n",
    "          'algo__min_samples_leaf': [1,5,10]},\n",
    "         \n",
    "         {'algo': [RandomForestClassifier()],\n",
    "          'algo__n_estimators': [100, 150, 200],\n",
    "          'algo__max_depth': [None, 10, 25, 50],\n",
    "          'algo__min_samples_leaf': [1,5,10],\n",
    "          'algo__n_jobs': [-1],\n",
    "          'algo__class_weight': [None, 'balanced'],\n",
    "          'algo__oob_score': [True, False]}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "excess-sitting",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-12T19:46:35.359994Z",
     "start_time": "2021-03-12T19:41:45.125880Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:   34.7s\n",
      "[Parallel(n_jobs=-1)]: Done 168 tasks      | elapsed:  2.9min\n",
      "[Parallel(n_jobs=-1)]: Done 250 out of 250 | elapsed:  4.8min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(RandomForestClassifier(class_weight='balanced', max_depth=25,\n",
       "                        min_samples_leaf=10, n_estimators=200, n_jobs=-1,\n",
       "                        oob_score=True),\n",
       " 0.6462578177081644)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand_trees = RandomizedSearchCV(estimator=pipe, \n",
    "                                param_distributions=trees, \n",
    "                                n_iter=50,\n",
    "                                cv=5, \n",
    "                                scoring='f1_weighted',\n",
    "                                n_jobs=-1,\n",
    "                                verbose=1,\n",
    "                                random_state=42)\n",
    "\n",
    "best_trees = rand_trees.fit(X_train, y_train)\n",
    "results = rand_trees.cv_results_\n",
    "\n",
    "best_trees.best_estimator_.get_params()['algo'], best_trees.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "revised-reggae",
   "metadata": {},
   "source": [
    "## Test Validation on best model\n",
    "\n",
    "After determining the best model from above, it appears that `RandomForestClassifier()` gave us the best model so far, and we can confirm this by comparing the predictions of this model compared to the validation sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "appointed-cuisine",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-12T19:46:35.468933Z",
     "start_time": "2021-03-12T19:46:35.361883Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score:          0.6109\n",
      "F1 weighted score: 0.6415\n",
      "Balanced accuracy: 0.6439\n"
     ]
    }
   ],
   "source": [
    "y_pred = best_trees.predict(X_validation)\n",
    "\n",
    "f1_weighted = f1_score(y_validation, y_pred, average = 'weighted')\n",
    "f1          = f1_score(y_validation, y_pred)\n",
    "bac         = balanced_accuracy_score(y_validation, y_pred)\n",
    "\n",
    "print(f'F1 score:          {f1:.4f}')\n",
    "print(f'F1 weighted score: {f1_weighted:.4f}')\n",
    "print(f'Balanced accuracy: {bac:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "radio-lindsay",
   "metadata": {},
   "source": [
    "As we can see, the weighted scores increased by roughly 0.07 compared to the intial model\n",
    "\n",
    "### Final Model\n",
    "\n",
    "From the `RandomizedSearchCV()` above, we can now fit a final model with determined hyperparameters(more runs could generate different hyperparameters as the search does not cover every possible combination)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "substantial-issue",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-12T19:46:37.055465Z",
     "start_time": "2021-03-12T19:46:35.470918Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('preprocessing',\n",
       "                 ColumnTransformer(transformers=[('categorical',\n",
       "                                                  Pipeline(steps=[('ohe',\n",
       "                                                                   OneHotEncoder(handle_unknown='ignore')),\n",
       "                                                                  ('imputer',\n",
       "                                                                   SimpleImputer(add_indicator=True,\n",
       "                                                                                 strategy='most_frequent'))]),\n",
       "                                                  age               False\n",
       "workClass          True\n",
       "education-num     False\n",
       "marital-status     True\n",
       "occupation         True\n",
       "relationship       True\n",
       "race               True\n",
       "sex                True\n",
       "native-country     True\n",
       "dtype: bool),\n",
       "                                                 ('...\n",
       "                                                                   StandardScaler()),\n",
       "                                                                  ('imputer',\n",
       "                                                                   SimpleImputer(add_indicator=True,\n",
       "                                                                                 strategy='median'))]),\n",
       "                                                  age                True\n",
       "workClass         False\n",
       "education-num      True\n",
       "marital-status    False\n",
       "occupation        False\n",
       "relationship      False\n",
       "race              False\n",
       "sex               False\n",
       "native-country    False\n",
       "dtype: bool)])),\n",
       "                ('rf',\n",
       "                 RandomForestClassifier(class_weight='balanced', max_depth=50,\n",
       "                                        min_samples_leaf=10, n_estimators=150,\n",
       "                                        n_jobs=-1, oob_score=True))])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe = Pipeline([('preprocessing', preprocessing), \n",
    "                 ('rf', RandomForestClassifier(class_weight='balanced',\n",
    "                                               max_depth=50,\n",
    "                                               min_samples_leaf=10,\n",
    "                                               n_estimators=150,\n",
    "                                               n_jobs=-1,\n",
    "                                               oob_score=True))])\n",
    "pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "tight-holly",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-12T19:46:37.161647Z",
     "start_time": "2021-03-12T19:46:37.057408Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score:          0.5984\n",
      "F1 weighted score: 0.6381\n",
      "Balanced accuracy: 0.6389\n"
     ]
    }
   ],
   "source": [
    "y_pred = pipe.predict(X_test)\n",
    "\n",
    "f1_weighted = f1_score(y_test, y_pred, average = 'weighted')\n",
    "f1          = f1_score(y_test, y_pred)\n",
    "bac         = balanced_accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(f'F1 score:          {f1:.4f}')\n",
    "print(f'F1 weighted score: {f1_weighted:.4f}')\n",
    "print(f'Balanced accuracy: {bac:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "australian-peoples",
   "metadata": {},
   "source": [
    "### Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "proof-steam",
   "metadata": {},
   "source": [
    "Given the lack of overall change in the metrics, there is more work needed to be done in terms of EDA. The F1 score getting lower tells us that the data is imbalanced and we could likely generate synthetic data using SMOTE during the next iteration to strengthen the model. The weighted scores increasing means I'm headed in the right direction.\n",
    "\n",
    "As of this iteration, it would not be useful in a business setting as there are not a strong prediction on future income based on this data.\n",
    "\n",
    "Next steps could include determining feature importance to highlight which fields are more important in determining an accurate outcome, and performing a grid search or expanding the random cross-validation search parameters to get a better model, although computationally more expensive."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
